{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d70d2eed-abdc-4eeb-8f45-170617a2961e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "block_size = 32\n",
    "batch_size = 64\n",
    "max_iters = 2000\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 50\n",
    "dropout = 0.2\n",
    "\n",
    "learning_rate = 3e-4\n",
    "n_embd = 384\n",
    "n_head = 8\n",
    "n_layer = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0450db6-68db-4627-963e-34690ba3326d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "with open ('wizard_of_oz.txt','r',encoding = 'utf-8') as f:\n",
    "    text = f.read()\n",
    "chars = sorted(set(text))\n",
    "print(chars)\n",
    "vocab_size = len(chars)\n",
    "print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdc668e4-b7bf-4155-9982-81dc7c594fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([233430])\n"
     ]
    }
   ],
   "source": [
    "string_to_int = {ch:i for i,ch in enumerate(chars)}\n",
    "int_to_string = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text),dtype = torch.long)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c9cecd2-a135-4484-96a6-0c99c17af0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186744\n",
      "46686\n",
      "inputs:\n",
      "tensor([[60, 73, 58,  ..., 10,  1, 64],\n",
      "        [ 1, 75, 63,  ...,  1, 60, 56],\n",
      "        [80, 60, 59,  ..., 63, 56, 69],\n",
      "        ...,\n",
      "        [68,  1, 64,  ...,  6, 74,  1],\n",
      "        [ 1, 61, 73,  ..., 63, 60,  1],\n",
      "        [ 1, 74, 71,  ...,  1, 69, 60]], device='cuda:0')\n",
      "targets:\n",
      "tensor([[73, 58, 80,  ...,  1, 64, 69],\n",
      "        [75, 63, 60,  ..., 60, 56, 73],\n",
      "        [60, 59,  1,  ..., 56, 69,  1],\n",
      "        ...,\n",
      "        [ 1, 64, 69,  ..., 74,  1, 57],\n",
      "        [61, 73, 76,  ..., 60,  1, 57],\n",
      "        [74, 71, 67,  ..., 69, 60, 64]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data =  data[n:]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    #print(len(data)-block_size)\n",
    "    ix = torch.randint(len(data)-block_size,(batch_size,))\n",
    "    #print(ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "print(x)\n",
    "print('targets:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59f7c282-a259-42c1-85fa-b0e26aa5703e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([82]) target is tensor(46)\n",
      "when input is tensor([82, 46]) target is tensor(63)\n",
      "when input is tensor([82, 46, 63]) target is tensor(60)\n",
      "when input is tensor([82, 46, 63, 60]) target is tensor(1)\n",
      "when input is tensor([82, 46, 63, 60,  1]) target is tensor(42)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42]) target is tensor(73)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73]) target is tensor(70)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70]) target is tensor(65)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65]) target is tensor(60)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60]) target is tensor(58)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58]) target is tensor(75)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75]) target is tensor(1)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1]) target is tensor(33)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33]) target is tensor(76)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76]) target is tensor(75)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75]) target is tensor(60)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60]) target is tensor(69)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69]) target is tensor(57)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69,\n",
      "        57]) target is tensor(60)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69,\n",
      "        57, 60]) target is tensor(73)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69,\n",
      "        57, 60, 73]) target is tensor(62)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69,\n",
      "        57, 60, 73, 62]) target is tensor(1)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69,\n",
      "        57, 60, 73, 62,  1]) target is tensor(60)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69,\n",
      "        57, 60, 73, 62,  1, 60]) target is tensor(28)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69,\n",
      "        57, 60, 73, 62,  1, 60, 28]) target is tensor(70)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69,\n",
      "        57, 60, 73, 62,  1, 60, 28, 70]) target is tensor(70)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69,\n",
      "        57, 60, 73, 62,  1, 60, 28, 70, 70]) target is tensor(66)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69,\n",
      "        57, 60, 73, 62,  1, 60, 28, 70, 70, 66]) target is tensor(1)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69,\n",
      "        57, 60, 73, 62,  1, 60, 28, 70, 70, 66,  1]) target is tensor(70)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69,\n",
      "        57, 60, 73, 62,  1, 60, 28, 70, 70, 66,  1, 70]) target is tensor(61)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69,\n",
      "        57, 60, 73, 62,  1, 60, 28, 70, 70, 66,  1, 70, 61]) target is tensor(1)\n",
      "when input is tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69,\n",
      "        57, 60, 73, 62,  1, 60, 28, 70, 70, 66,  1, 70, 61,  1]) target is tensor(30)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(\"when input is\",context,\"target is\",target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "238d126a-dbd6-4b1a-89ff-972538ea747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "       \n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)  \n",
    "        q = self.query(x) \n",
    "      \n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 \n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) \n",
    "        wei = F.softmax(wei, dim=-1) \n",
    "        wei = self.dropout(wei)\n",
    "      \n",
    "        v = self.value(x) \n",
    "        out = wei @ v \n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "  \n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "    \n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "   \n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "       \n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x + y)\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x + y)\n",
    "        return x\n",
    "    \n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        B, T = index.shape\n",
    "        \n",
    "        \n",
    "     \n",
    "        tok_emb = self.token_embedding_table(index) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb \n",
    "        x = self.blocks(x) \n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            \n",
    "            index_cond = index[:, -block_size:]\n",
    "            \n",
    "            logits, loss = self.forward(index_cond)\n",
    "           \n",
    "            logits = logits[:, -1, :] \n",
    "           \n",
    "            probs = F.softmax(logits, dim=-1) \n",
    "            \n",
    "            index_next = torch.multinomial(probs, num_samples=1) \n",
    "           \n",
    "            index = torch.cat((index, index_next), dim=1)\n",
    "        return index\n",
    "\n",
    "model = GPTLanguageModel(vocab_size)\n",
    "\"\"\"print(\"loading model parameters...\")\n",
    "with open('model_01.pkl','rb') as f:\n",
    "    model = pickle.load(f)\n",
    "print(\"Loaded Successfully\")\"\"\"\n",
    "m = model.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72d64a8a-cb17-479f-a9a4-55366e18faa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ")h5s*07ddun﻿Y*R5V_iV9\n",
      "IdD0h,r8yAU1FI28;3y3kvh*Upit*lnV/V'SsrOKpiKBV:pN5gKt4Y(/(Lywwdd#o\n",
      "2!Yw:c7kV\n",
      "9[XLWo\n",
      "3CsSikaQ/QP:s/7bxP\n",
      "2;\n",
      "oDxTEFwduc/\"rgE*Q*9]2ub50r EmNKsWsU1Z3a6L\"MI69.ST]vIu::cSiQ#h\"lXFX9[7XG&Tg n3HkAXhYO6XT3E9)Y-g9Qs#cBT#Bmo)Ix1rV\n",
      "efDO(K﻿KA,q1zQ'\"lxq0&LY(b/\"- _AW*t U(-C/'CP?\"fhe8G8/vdDOka:G(- ud?W'3rNA)lCjRX0_3X9-a,D)luccC,p[/Qg#wUbFgjOPmrV'jcTv5b/RN&EFtJduB'\"\"8IRU3jaQOa-Q﻿Mk:mIam?DxNW7GOam;e,l(;qrV3\n",
      "SHf9Nnk&sFOX8YG(yR-_o1]2 rV_﻿XTxBAMF[i9LbTb_G(IsFueTM.(kWj;rKchk1r&zbqYtbyc?5VAU&dd3m:p\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
    "\n",
    "    def forward(self,index,targets = None):\n",
    "        logits = self.token_embedding_table(index)\n",
    "        \n",
    "       \n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits,targets)\n",
    "            \n",
    "            \n",
    "\n",
    "        return logits, loss \n",
    "\n",
    "    def generate(self,index,max_new_tokens):\n",
    "        for i in range(max_new_tokens):\n",
    "            logits , loss = self.forward(index)\n",
    "\n",
    "            logits = logits[:,-1,:]\n",
    "\n",
    "            probs = F.softmax(logits,dim=-1)\n",
    "\n",
    "            index_next = torch.multinomial(probs,num_samples = 1)\n",
    "\n",
    "            index = torch.cat((index,index_next),dim=1)\n",
    "        return index\n",
    "\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "\n",
    "context = torch.zeros((1,1) , dtype= torch.long,device = device)\n",
    "generated_chars = decode(m.generate(context,max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce311788-ba75-4799-9c23-94dc06d40c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train','val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X,Y = get_batch(split)\n",
    "            logits,loss = model (X,Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b17985e4-1520-4516-b6a9-26266d5c4c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train_loss: 4.470 , val_loss: 4.468\n",
      "step: 50, train_loss: 2.463 , val_loss: 2.513\n",
      "step: 100, train_loss: 2.281 , val_loss: 2.340\n",
      "step: 150, train_loss: 2.099 , val_loss: 2.188\n",
      "step: 200, train_loss: 1.943 , val_loss: 2.049\n",
      "step: 250, train_loss: 1.824 , val_loss: 1.955\n",
      "step: 300, train_loss: 1.767 , val_loss: 1.886\n",
      "step: 350, train_loss: 1.705 , val_loss: 1.836\n",
      "step: 400, train_loss: 1.654 , val_loss: 1.798\n",
      "step: 450, train_loss: 1.615 , val_loss: 1.753\n",
      "step: 500, train_loss: 1.577 , val_loss: 1.741\n",
      "step: 550, train_loss: 1.555 , val_loss: 1.718\n",
      "step: 600, train_loss: 1.515 , val_loss: 1.690\n",
      "step: 650, train_loss: 1.489 , val_loss: 1.673\n",
      "step: 700, train_loss: 1.460 , val_loss: 1.659\n",
      "step: 750, train_loss: 1.439 , val_loss: 1.652\n",
      "step: 800, train_loss: 1.424 , val_loss: 1.648\n",
      "step: 850, train_loss: 1.405 , val_loss: 1.623\n",
      "step: 900, train_loss: 1.395 , val_loss: 1.626\n",
      "step: 950, train_loss: 1.380 , val_loss: 1.598\n",
      "step: 1000, train_loss: 1.355 , val_loss: 1.615\n",
      "step: 1050, train_loss: 1.355 , val_loss: 1.592\n",
      "step: 1100, train_loss: 1.331 , val_loss: 1.588\n",
      "step: 1150, train_loss: 1.334 , val_loss: 1.594\n",
      "step: 1200, train_loss: 1.303 , val_loss: 1.562\n",
      "step: 1250, train_loss: 1.292 , val_loss: 1.578\n",
      "step: 1300, train_loss: 1.285 , val_loss: 1.562\n",
      "step: 1350, train_loss: 1.276 , val_loss: 1.554\n",
      "step: 1400, train_loss: 1.256 , val_loss: 1.553\n",
      "step: 1450, train_loss: 1.255 , val_loss: 1.560\n",
      "step: 1500, train_loss: 1.247 , val_loss: 1.559\n",
      "step: 1550, train_loss: 1.238 , val_loss: 1.538\n",
      "step: 1600, train_loss: 1.226 , val_loss: 1.558\n",
      "step: 1650, train_loss: 1.218 , val_loss: 1.560\n",
      "step: 1700, train_loss: 1.211 , val_loss: 1.557\n",
      "step: 1750, train_loss: 1.195 , val_loss: 1.547\n",
      "step: 1800, train_loss: 1.185 , val_loss: 1.532\n",
      "step: 1850, train_loss: 1.182 , val_loss: 1.544\n",
      "step: 1900, train_loss: 1.180 , val_loss: 1.527\n",
      "step: 1950, train_loss: 1.171 , val_loss: 1.542\n",
      "1.2175054550170898\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(),lr = learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    print(iter)\n",
    "   \n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step: {iter}, train_loss: {losses['train']:.3f} , val_loss: {losses['val']:.3f}\")\n",
    "\n",
    "    xb,yb = get_batch('train')\n",
    "\n",
    "    logits,loss = model.forward(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none = True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad5c6fc6-5c85-42f0-a1b7-900ed8ff2e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "which to be a mountern to the long Very, and khen diffivied at the perface best thing the Prince joined Dorothy\n",
      "and the cannot brought that your kicken; better usee them.\"\n",
      "\n",
      "\"But the gat wasbers of our doompway, who the horse told. Just\n",
      "was ripers cuase of the Mangagaabooo\n",
      "Chad CFlight us, anxiously, \"because the readful regrospleen lyings glass\n",
      "delyhbod upon the breath. They were\n",
      "too ruished wooden; but it was sdmy.\n",
      "\n",
      "Then it mure be s\n",
      "near while many be accross that he heart upon.\n",
      "\n",
      "\"No one of th\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1) , dtype= torch.long,device = device)\n",
    "generated_chars = decode(m.generate(context,max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9db348-6f58-4467-8fe1-5a19e859af08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d0ed53-3983-41af-b0d2-ccbde0362ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
